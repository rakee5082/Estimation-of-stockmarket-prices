{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import describe\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from numpy.random import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.externals import joblib\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "def series_to_supervised(data,columns,index, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [(columns[j]+'(t-%d)' % (i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [(columns[j]+'(t)')for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [(columns[j]+'(t+%d)' % (i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\tagg.index = index\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "\n",
    "def read_data(obj):\n",
    "    ## get ticker data\n",
    "    ticker = pd.read_csv('../data/'+obj+'_ticker.csv', index_col=0, header=None)\n",
    "    ticker.index = pd.to_datetime(ticker.index, unit='s')\n",
    "    ticker.index.name = None\n",
    "    ticker.columns = [\n",
    "        'sell_highest_price', \n",
    "        'sell_highest_vol', \n",
    "        'buy_highest_price', \n",
    "        'buy_highest_vol', \n",
    "        'last_trade_price', \n",
    "        'daily_trade_vol', \n",
    "        'daily_high_price', \n",
    "        'daily_low_price'\n",
    "    ]\n",
    "    ticker.values[np.where(ticker.values <= 0)] = np.nan\n",
    "    ticker = ticker.interpolate()\n",
    "    ## trades data\n",
    "    trades = pd.read_csv('../data/'+obj+'_trades.csv', index_col=0, header=None) \n",
    "\n",
    "    ## get book data\n",
    "    book = pd.read_csv('../data/'+obj+'_book.csv', index_col=0, header=None)    \n",
    "    ticker = ticker.add_suffix(obj)\n",
    "    return ticker,trades,book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metals = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
    "ticker = {'A':[], 'B':[], 'C':[], 'D':[], 'E':[], 'F':[], 'G':[], 'H':[], 'I':[]}\n",
    "trades = {'A':[], 'B':[], 'C':[], 'D':[], 'E':[], 'F':[], 'G':[], 'H':[], 'I':[]}\n",
    "book = {'A':[], 'B':[], 'C':[], 'D':[], 'E':[], 'F':[], 'G':[], 'H':[], 'I':[]}\n",
    "models = {'A':[], 'B':[], 'C':[], 'D':[], 'E':[], 'F':[], 'G':[], 'H':[], 'I':[]}\n",
    "for currency in metals:\n",
    "    ticker[currency],trades[currency],book[currency] = read_data(currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cur_met in metals:\n",
    "    ########## get statistics of each 5 min in vopr - price and vol trade \n",
    "    trades[cur_met].replace(-1,np.NaN)\n",
    "\n",
    "    temp_price_trade = trades[cur_met].iloc[:,3::4]\n",
    "    temp_vol_trade = trades[cur_met].iloc[:,2::4]\n",
    "    temp_vopr_trade = pd.DataFrame(trades[cur_met].iloc[:,3::4].values * trades[cur_met].iloc[:,2::4].values)\n",
    "    temp = np.sum(np.absolute(temp_vopr_trade.get_values()),axis=1) / np.sum(np.absolute(temp_vol_trade.get_values()),axis=1)\n",
    "    absvopr = {'absvopr' : temp}\n",
    "    absvopr = pd.DataFrame.from_dict(absvopr)\n",
    "\n",
    "    K = 10\n",
    "    ### set index of dataframe to time and merger data \n",
    "    absvopr.index = ticker[cur_met].index\n",
    "    ### merge step ticker and trade\n",
    "    imp_ticker = ticker[cur_met].iloc[:,[0,2,4,7]]    \n",
    "    stock = pd.DataFrame(index=ticker[cur_met].index)\n",
    "    stock = pd.merge(imp_ticker,absvopr, left_index=True, right_index=True) ## y\n",
    "    other_stock = pd.DataFrame(index=ticker[cur_met].index)\n",
    "    for currency in metals:\n",
    "        if(currency!=cur_met):\n",
    "            ticker[currency].index = ticker[cur_met].index\n",
    "            temp_tic = ticker[currency].iloc[:,:]\n",
    "            other_stock = pd.merge(other_stock,temp_tic, left_index=True, right_index=True)\n",
    "    other_stock.head()\n",
    "\n",
    "    all_feat = [u'sell_highest_price',u'buy_highest_price',u'last_trade_price']\n",
    "    all_feat = [x+cur_met for x in all_feat]\n",
    "    all_feat.append(u'absvopr')     \n",
    "\n",
    "    temp_stock = stock.loc[:,all_feat];\n",
    "    data_stock_raw = series_to_supervised(temp_stock.values,temp_stock.columns.get_values(),temp_stock.index,25, 11)\n",
    "    other_data_raw = other_stock\n",
    "   \n",
    "    #### set feature name \n",
    "    input_feat = temp_stock.columns\n",
    "    past_feat = [0,1,2,5,7,9,10]\n",
    "    input_names = []\n",
    "    for i in past_feat:\n",
    "        if (i==0):\n",
    "            input_names += [(input_feat[j]+'(t)')for j in range(len(input_feat))]\n",
    "        else:\n",
    "             input_names += [(input_feat[j]+'(t-%d)' % (i))for j in range(len(input_feat))]\n",
    "\n",
    "\n",
    "    output_feat = temp_stock.columns[2]\n",
    "    fut_feat = list(range(10))\n",
    "    fut_feat = []\n",
    "    for i in range(1,11):\n",
    "         temp = []\n",
    "         temp.append(output_feat+'(t+%d)' % (i))\n",
    "         fut_feat.append(temp)\n",
    "\n",
    "    f_model1 =ExtraTreesRegressor(n_estimators=1, max_features='sqrt',n_jobs=-1,\n",
    "                                        random_state=0)\n",
    "    f_model2 =ExtraTreesRegressor(n_estimators=1, max_features='sqrt',n_jobs=-1,\n",
    "                                        random_state=0)\n",
    "    # create pipeline\n",
    "    estimators = []\n",
    "    estimators.append(('feature_selection', SelectFromModel(f_model1)))\n",
    "    estimators.append(('lin', f_model2))\n",
    "    pip = Pipeline(estimators)\n",
    "    \n",
    "    data =  pd.concat([other_data_raw, data_stock_raw.loc[:,input_names]], axis=1, join='inner')\n",
    "\n",
    "    ##### produce input\n",
    "    poly = PolynomialFeatures(interaction_only=True,include_bias = False)\n",
    "    X_t = data.loc[:,input_names].get_values()\n",
    "    X_t = StandardScaler().fit_transform(X_t)    \n",
    "    X_t = poly.fit_transform(X_t)\n",
    "    Y = data_stock_raw.loc[:,sum(fut_feat, [])].get_values()\n",
    "    pip.fit(X_t,Y)\n",
    "    pkl_filename = 'my_model/model'+cur_met+'.pkl'  \n",
    "    joblib.dump(pip, pkl_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(pkl_filename, 'wb') as handle:\n",
    "    pickle.lo, handle)\n",
    "    handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mylist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-802bfd1f9983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mylist' is not defined"
     ]
    }
   ],
   "source": [
    "', '.join(fe)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
